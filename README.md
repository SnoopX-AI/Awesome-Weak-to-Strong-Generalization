# Awesome-Weak-to-Strong-Generalization
All the papers listed in this project come from my usual reading.
If you have found some new and interesting papers, I would appreciate it if you let me know!!! 


https://arxiv.org/abs/2312.09390
[2407.13647] Weak-to-Strong Reasoning (arxiv.org)
[2401.06751] The Unreasonable Effectiveness of Easy Training Data for Hard Tasks (arxiv.org)
[2403.09472] Easy-to-Hard Generalization: Scalable Alignment Beyond Human Supervision (arxiv.org)
[2404.10642] Self-playing Adversarial Language Game Enhances LLM Reasoning (arxiv.org)
[2405.16043] Theoretical Analysis of Weak-to-Strong Generalization (arxiv.org)
[2402.03749] Vision Superalignment: Weak-to-Strong Generalization for Vision Foundation Models (arxiv.org)
[2402.15505] Co-Supervised Learning: Improving Weak-to-Strong Generalization with Hierarchical Mixture of Experts (arxiv.org)
[2405.15116] Quantifying the Gain in Weak-to-Strong Generalization (arxiv.org)
[2407.19594] Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge (arxiv.org)
[2405.04086] Optimizing Language Model's Reasoning Abilities with Weak Supervision (arxiv.org)
[2405.17888] Getting More Juice Out of the SFT Data: Reward Learning from Human Demonstration Improves SFT for LLM Alignment (arxiv.org)
[2406.11431] Super(ficial)-alignment: Strong Models May Deceive Weak Models in Weak-to-Strong Generalization (arxiv.org)
[2407.00497] LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement (arxiv.org)
[2406.03199] Bayesian WeakS-to-Strong from Text Classification to Generation (arxiv.org)
[2406.11741] Transcendence: Generative Models Can Outperform The Experts That Train Them (arxiv.org)
[2405.19262] Weak-to-Strong Search: Align Large Language Models via Searching over Small Language Models (arxiv.org)
[2407.04622] On scalable oversight with weak LLMs judging strong LLMs (arxiv.org)
